\head{Остовные деревья и кратчайшие пути}
Мы продолжаем изучать графы, и сегодня займёмся поиском \term{минимального остовного дерева} — остовного дерева в неориентированном графе с минимальным суммарным весом рёбер, и модификациями данной задачи, а после этого будем искать \term{кратчайшие пути} между парой вершин, от одной вершины до всех остальных и между всеми парами вершин. Хоть алгоритмов и много, но все они (почти) достаточно понятны и частично основываются на уже пройденных алгоритмах.


\subhead{Минимальное остовное дерево}
На самом деле, раньше мы уже находили остовные деревья, когда совершали обходы графа (для DFS это дерева строится рекурсией, а для BFS дерево создаётся из рёбер, помещающих новые вершины в очередь). Поэтому если наш граф невзвешенный, то мы можем считать все веса рёбер равными 1, а значит любое остовное дерево будет являться минимальным, то есть мы уже частично умеем решать задачу. Но для взвешенных графов алгоритм не такой простой, поэтому перейдём к его изучению.

\textbf{Алгоритм Прима.} Это своего рода модификация алгоритмов обхода графа, потому что запустимся мы от одной вершины и рёбра будем добавлять последовательно (так, что всё время будем иметь дерево). Также нам понадобится знать, какие вершины уже в дереве (список $used$) и структура данных, позволяющая быстро выбирать минимальный элемент (множество / отображение или куча), назовём её $p$. И алгоритм выглядит так:

\begin{enumerate}
    \item Произвольно выберем стартовую вершину $u$, пометим её в $used$ и добавим все рёбра $(u, v)$ в $p$, при этом $p$ должна уметь выдавать ребро с минимальным весом.
    \item Теперь пока структура $p$ не пуста будем брать из неё минимальное ребро $(u, v)$ и удалять его из $p$. Если так оказалось, что обе вершины ($u$ и $v$) уже в дереве (помечены как $used$), то ребро нужно пропустить. А иначе мы добавляем ребро $(u, v)$ в итоговое дерево, помечаем $v$ как $used$ ($u$ уже в дереве, потому что ребро оказалось в $p$) и добавляем в $p$ все рёбра $(v, t)$, где $t$ ещё не в дереве (не $used$), чтобы избежать зацикливания.
\end{enumerate}

Понятно, почему такой алгоритм работает, ведь из уже существующего минимального дерева какое-то ребро провести придётся и поэтому мы выбираем максимальное. А раз мы так делаем пока все доступные рёбра не получатся, то мы как раз получим минимальное остовное дерево текущей компоненты связности. Если же ещё есть другие КС, то будем запускать построение дерева от каких-то вершины из них и в итоге получим минимальный остовный лес.

Чем полезен такой алгоритм, так это возможностью смотреть не на все рёбра, а только на их часть, при выборе следующего ребра. Также для этого алгоритма граф должен быть представлен как список смежности, что тоже удобно, потому он применим в большом количестве других задач. 

Сложность такого алгоритма составляет \O{m \log m}, так обрабатывается $m$ рёбер и на каждое из них тратится \O{\log m}, ведь его нужно добавить в $p$ и достать из неё, а делается это не быстрее, чем за логарифм размера $p$. Также можно улучшить алгоритм до \O{m \log n}, если для каждой вершины хранить только минимальное ребро, ведущее в неё, но даже если считать, что в графе много рёбер, то $m = O(n^2)$ и $O(m \log m) = O(m \log n^2) = O(2m \log n) = O(m \log n)$, поэтому фактически улучшение может и не быть.

\textbf{Алгоритм Краскала.} Этот алгоритм сильно отличается от предыдущего, но схож тем, что на очередном шаге выбирает минимальное ребро. Для алгоритма нам понадобится список рёбер $e$, список $used$ посещённых вершин и структура $p$, позволяющая объединять множества и проверять элементы на принадлежность одному множеству (в простейшем случае можно использовать массив, но с DSU будет быстрее):

\begin{enumerate}
    \item Для начала отсортируем $e$ по неубыванию веса, а в структуре $p$ размера $n$ сохраним, что все вершины пока принадлежат разным множествам (деревьям).
    \item Теперь будем перебирать все рёбра от меньшего веса к большему и если очередное ребро $(u, v)$ соединяет разные деревья, то это ребро нужно добавить к итоговому дереву и в $p$ объединить множества, представленные $u$ и $v$.
\end{enumerate}

Понятно, что и этот алгоритм тоже работает, ведь когда мы добавляем ребро $(u, v)$, то соединяем множество вершины $u$ с остальным деревом, и делаем мы это ребром с минимальным доступным весом. А значит и получаем в конце минимальное остовное дерево для связного графа и минимальный остовный лес для несвязного графа.

Сложность же алгоритма также составляет \O{m \log n}, ведь нам требуется $O(m \log m) = O(m \log n^2) = O(2m \log n) = O(m \log n)$ на сортировку рёбер и после этого мы выполняем \O{m} операций с $p$, которые в DSU можно реализовать за \O{\ac{n}}, то есть итого имеем $O(m \log n + m \ac{n}) = O(m \log n)$. Также важно, что этому алгоритму, в отличие от предыдущего, требуется список рёбер, что может быть несколько не удобно, но в зато этот алгоритм будет легко модифицировать, что мы дальше и увидим.


\subhead{Модификации минимального остова}
Искать только минимальное остовное дерево — это скучно, поэтому существуют другие схожие задачи, которые решаются теме же алгоритмами, что мы и прошли, после внесения небольших изменений. При этом нам будет проще вносить изменения в алгоритм Краскала, но некоторые задачи также решаемы и с помощью алгоритма Прима. Рассмотрением этих задач мы и займёмся.

\textbf{Максимальное остовное дерево.} В общем-то понятно, что здесь нужно сделать: раз у нас вместо минимума нужно найти максимум, то достаточно поменять правило сортировки на противоположное. То есть, для алгоритма Прима мы будем выбирать ребро с максимальным весом, а для алгоритма Краскала будем идти от рёбер с большим весом к рёбрам с меньшим весом. Но можно поступить более олимпиадно и поменять все веса $w \to -w$ и использовать уже их в обычных алгоритмах :)

\textbf{Минимальное достроение.} Пусть у нас в графе уже выбраны какие-то рёбра и нам нужно ещё выбрать какие-то рёбра так, чтобы суммарный вес был минимальным и количество компонент связности было таким же, как и в исходном графе.

Решить эту задачу также не сложно с помощью алгоритма Краскала. Для этого, перед запуском основного алгоритма, добавим все обязательные рёбра к результату и отметим в $p$, что какие-то множества соединены ребром. А после этого сделаем обычный запуск алгоритма Краскала.

\textbf{Лес из заданного числа компонент связности.} Пусть нам требуется найти минимальный остовный лес, но при этом он должен состоять из $k$ компонент связности (где $k$ не меньше, чем количество исходных КС).

Это тоже достаточно простая задача, ведь алгоритм Краскала на каждом шаге действует жадно, поэтому его достаточно будет прервать, когда останется $k$ компонент связности. Определить же это можно посчитав количество добавленных рёбер, их должно быть $m' = n - k$, ведь в каждой КС рёбер $m'_i = n_i - 1$ (так как это деревья), а всего $n = \sum\limits_{i = 1}^{k} n_i$, а значит $m' = \sum\limits_{i = 1}^{k} m_i = \sum\limits_{i = 1}^{k} (n_i - 1) = \sum\limits_{i = 1}^{k} n_i - k = n - k$. Такую же формулу можно получить, если учесть, что изначально мы имеем $n$ КС, а должны сделать $k$ КС, при этом каждое проводимое ребро объединяет две КС, а значит $m' = n - k$.

\textbf{Минимакс и максимин.} Минимаксом называет поиск пути между вершинами $i$ и $j$ такой, что вес этого пути минимален. При этом весом пути называется максимальной вес ребра, которые встречается на этом пути. Аналогично определяется максимин, там нужно максимизировать минимальный вес ребра на пути.

Если подумать, то оказывается, что искомый путь будет лежать в минимальном остовном дереве. В самом деле, при построении минимального остовного дерева мы на каждом шаге выбираем минимальное ребро, а значит и на пути между $i$ и $j$ добавляется ребро с минимальным возможным весом, а следовательно максимальный вес среди них действительно минимально возможный.

Итоговым алгоритмом будет: сначала найти минимальное остовное дерево, а после этого запустить какой-нибудь обход графа и найти максимальное значение на пути между $i$ и $j$. Итоговая сложность будет такой же, как и у построения дерева, ведь его обход выполняется за линейное время (так как в дереве имеем $m = n - 1$, и алгоритмы обхода отработают за $O(n + m) = O(n + n - 1) = O(n)$).

\textbf{Второе лучшее остовное дерево.} В этой задаче требуется найти не минимальное остовное дерево, а второе по минимальности. Это задача уже не такая очевидная, и сложность у неё получится несколько больше.

Заметим, что второе по минимальности остовное дерево можно получить, если произвести всего одну замену в обычном минимальном остовном дереве (то есть одно ребро удалить и одно добавить). И понятно, почему это условие выполняется, ведь если мы производим замену, то от этого суммарный вес дерева только увеличивается, а если делать несколько таких замен, то вес увеличится ещё больше. Следовательно, второе лучшее дерево отличается от лучшего всего одной заменой.

А раз так, то сначала построим первое лучшее дерево, а потом будем по очереди запрещать использовать его рёбра и строить новые минимальные остовные деревья. Тогда нам потребуется \O{m \log n} на первоначальную сортировку, \O{m} на поиск лучшего оствного дерева и после этого мы будим закрывать \O{n} рёбер, тратя на каждое ещё один поиск лучшего остовного дерева за \O{m}. И итоговая сложность будет \O{nm}. Но стоит отметить, что можно ускорить алгоритм, если использовать DSU или LCA, но это уже остаётся на изучение читателю :)


\subhead{Кратчайшие пути от одной вершины до всех}
С минимальными остовными деревьями мы разобрались, поэтому можем переходить к кратчайшим путям. При этом хотелось бы начать с кратчайшего пути между парой вершин, но для этой задачи нет отдельного алгоритма, поэтому мы начнём с кратчайшего пути из одной вершины во все.

Оказывается, что и эту задачу мы уже умеем решать для невзвешенных графов с помощью BFS. Для этого в BFS будем поддерживать $d_i$ — номер слоя для вершины $i$, который нужно пересчитывать при добавлении вершины $i$ в очередь из-за ребра $x \to i$, как $d_i = d_x + 1$. Но всё же это частный случай для невзвешенных графов, а хочется уметь решать задачу в общем виде, поэтому перейдём к изучению алгоритмов для взвешенных графов.

\textbf{Алгоритм Дейкстры.} Этот алгоритм похож на смесь BFS и алгоритма Прима. И своей целью ставит определение $d_i$ — расстояние от стартовой вершины $s$ до вершины $i$. При этом во время работы алгоритма нам понадобится брать вершину с минимальным расстоянием, и из-за разных способов это сделать мы будем получать разные сложности.

\begin{enumerate}
    \item Положим $d_s = 0$ и $d_u = \infty$\footnote{Здесь и далее константу $\infty$ нужно выбирать так, чтобы сумма $\infty + \infty$ ещё входила в тип данных!}, для $u \ne s$.
    \item Теперь в цикле будем выбирать необработанную вершину $u$ с минимальным расстоянием до ней (как это делать будет описано ниже). Обходим все рёбра $(u; v)$ и пытаемся обновить минимальное расстояние $d_v = \min(d_v, d_u + c)$, где $c$ — это стоимость ребра $(u, v)$.
\end{enumerate}

Собственно, это и есть весь алгоритм, теперь осталось понять, как искать вершину $u$.

Выбирать вершину $u$ можно с помощью массивов. Для этого дополнительно будем поддерживать список $used$, отвечающий за посещённость вершины (будем отмечать вершину $u$ в $used$, до обхода рёбер из $u$). И теперь для выбора минимальной вершины будем проходить по всем вершинам и выбирать ту, у которой $d_i$ минимальна и при этом она ещё не посещалась согласно списку $used$. Заканчивать же алгоритм мы можем или когда посещены все вершины, или когда посещена все КС (тогда мы сможем найти только $d_i = \infty$ среди не посещённых вершин).

Другой способ — это использовать множество / отображение или кучу $p$. Тогда в самом начале нам нужно добавить пару $(0; s)$ в $p$. А после этого на каждом шаге брать минимальную пару $(u, c)$ из $p$ и уже работать с этой вершиной. При этом после изменения расстояния до вершины $v$ нам нужно добавить ей в $p$ (в таком же формате $(v, d_v)$). Но понятно, что так одна и та же вершина $v$ может попасть в $p$ из-за разных вершин $u$, а обрабатывать мы её хотим только один раз. Поэтому если нам позволяет структура данных $p$, то перед добавлением нужно будет удалить старое значение для вершины $v$, что мы и будем делать для встроенных в C++ множеств и отображений, а также для самописной кучи. А если же мы используем встроенную в C++ кучу, то операции удаления в ней нет, поэтому обходить все рёбра из $u$ мы будем только в случае, когда $c = d_u$ (то есть между добавлением пары в кучу и обновлением вершин не было других обновлений). Заканчивать же алгоритм мы в любом случае будем, когда $p$ станет пусто.

Алгоритм, конечно, хороший и понятный, но в общем есть одна проблема — он не всегда работает. Пусть мы уже правильно обработали какое-то множество вершин (нашли кратчайшие пути до них) и все рёбра, выходящие из них, а сейчас обрабатываем вершину $u$. Тогда для неё $d_u$ будет правильным ответом только если нет рёбер отрицательного веса $w$, ведь если они существуют, то может найтись ещё какая-то вершина $x$ такая, что $d_x > d_u$, но при этом $d_x + w < d_u$, а значит для вершину $u$ у нас пока не правильный ответ. Но вот если все веса неотрицательны то точно всё хорошо, ведь тогда для любого $x$ будем иметь $d_x > d_u$ и $d_x + w > d_u$.

Поэтому алгоритм Дейкстры работает только для графов без рёбер отрицательного веса, а его сложность для случая с массивами будет \O{n^2 + m}, потому что мы для каждого шага перебираем все вершины и плюс просматриваем все ребра. А вот если использовать правильные структуры данных, то имеем сложность \O{m \log n}, потому что в худшем случае каждое ребро обновляет кратчайшие пути, а на одну операцию с $p$ требуется $O(\log n)$ операций в случаи с удаление повторов и $O(\log m) = O(\log n^2) = O(2 \log n) = O(\log n)$ если повторы не удалять :) Всего же таких операций $m$ для рёбер 
$n$ для взятия минимальной вершины, поэтому на самом деле сложность составляет \O{(n + m) \log n}.

Также стоит сказать, что есть решение со сложностью \O{n \log n + m}, если использовать \term{Фибоначчиевы кучи}, и линейный алгоритм Торупа, но это тоже остаётся для самостоятельного изучения читателями.

\textbf{Алгоритм Форда–Беллмана.} На самом деле, разобранная выше реализация алгоритма Дейкстры на основе кучи без удаления лишних пар всё же умеет обрабатывать отрицательные веса рёбер (просто работает несколько дольше, потому что делает несколько обновлений для одной вершины), но ломается, если в графе есть цикл отрицательного веса (обновления в алгоритме Дейкстры происходят бесконечно). Именно для этого и нужно использовать очень простой алгоритм Форда–Беллмана, вычисляющий $d_i$ минимальное расстояние от $s$ до $i$:

\begin{enumerate}
    \item Изначально принимаем $d_s = 0$ и $d_u = \infty$, для $u \ne s$.
    \item Теперь повторим цикл $n-1$ раз, в каждом из которых для всех рёбер $(u, v)$ с весом $c$ сделаем \term{релаксацию} (обновление ответа): $d_v = \min(d_v, d_u + c)$. 
\end{enumerate}

И это собственно весь алгоритм!

А если нужно проверить, есть ли цикл отрицательного веса, то достаточно ещё раз сделать релаксацию для всех рёбер и проверить, поменялись ли ответы: если поменялись, то есть цикл отрицательного веса, если нет — то и цикла нет. Просто, правда? :)

Но и в таком простом алгоритме можно сделать пару модификаций. Во-первых, если на каком-то шаге не один $d_i$ не обновился, то у нас уже есть ответ. А во-вторых, если нужно, то можно восстановить сами кратчайшие пути (как, собственно, и в алгоритме Дейкстры).

Теперь быстренько докажем правильность этого алгоритма. Заметим, что на $i$-ой итерации цикла мы получаем правильные ответы для всех вершин, кратчайшие расстояния до которых состоят из $i$ рёбер. Это утверждение очевидно, ведь на первом шаге мы посетим первое ребро и получим оптимальный ответ для первой вершины, на втором шаге точно посмотрим на второе ребро пути и получим ответ для второй вершины, и так далее, а на $i$-ом шаге как раз пройдём по $i$-ому ребро и получим ответ для этой вершины. А поскольку граф состоит из $n$ вершин, то самый длинный путь может состоять из $n - 1$ ребра, именно столько итераций цикла мы и делаем, а значит наш алгоритм корректен.

Также стоит сказать, что граф можно хранить и как список рёбер, и как список смежности, и тогда сложность этого алгоритма \O{n m}, хоть это читатель мог понять и сам :) А вот если мы работаем с матрицей смежности, то на каждом шаге цикла будем проходить всю матрицу и получим сложность \O{n^3}.


\subhead{Кратчайшие пути между всеми парами вершин}
Раз уж мы решали задачу для случая с одной стартовой вершиной, то теперь совсем усложним её и будем искать путь между всеми парами вершин. Наивные решения, которые $n$ раз бы запускали поиск расстояния от одной вершины нас не интересуют, потому что они получатся слишком сложными для $m = O(n^2)$: \O{n^3 \log n} для алгоритма Дейкстры и \O{n^4} для алгоритма Форда–Беллмана, а хочется найти алгоритм быстрее. Поэтому, можно бы начать бояться, что тут будет какой-нибудь очень сложный алгоритм, но на самом деле всё просто:

\begin{enumerate}
    \item Сохраним граф в матрице смежности $g$ и в ячейку $(i, j)$ поставим $\infty$, если в графе нет ребра из $i$ в $j$, а иначе запишем в эту ячейку вес самого ребра. Также считаем, что в вершине можно оставаться: $g_{i \to i} = 0$ (если в графе разрешены петли, то пишем вес петель).
    \item Теперь сделаем цикл $n$ раз и на $k$-ом шаге цикла переберём все пары вершин $(i, j)$ и будем пытаться обновить ответ для этой пары через вершину $k$: $g_{i \to j} = \min(g_{i \to j}, g_{i \to k} + g_{k \to j})$.
\end{enumerate}

Вот и всё, мы получили рабочий алгоритм в 3 цикла и одну операцию!

Давайте докажем этот алгоритм, который основывается на динамическом программировании. Пусть $D_{i \to j}^k$ это оптимальный путь из $i$ в $j$, промежуточно проходящий только через первые $k$ вершин: $1,\ 2,\ \ldots,\ k$. Тогда понятна и основная формула перехода: $D_{i \to j}^{k + 1} = \min( D_{i \to j}^k, D_{i \to k}^k + D_{k \to j}^{k})$, ведь очередная вершина $k$ может как использоваться в пути $i \to j$, так и нет. Базой же динамики будут изначальные кратчайшие расстояния, не проходящие через другие вершины, которые являются весами рёбер: $k = 0$ и $D_{i \to j}^0 = g_{i \to j}$.

Но поскольку в нашей формуле мы вычисляем $D^{k + 1}$ только через $D^k$, то для ответов можно хранить не трёхмерную матрицу $n \times n \times k$, а ограничиться лишь двумя матрицами $n \times n$. А если понять, что от рассмотрения лишних вершин наш ответ не ухудшится, то можно смело хранить ответы для обоих итераций ($k$ и $k + 1$) в одном и том же массиве, именно поэтому мы и имеем такую простую формулу для алгоритма Флойда–Уоршелла (так называется то, что мы прошли).

Понятно, что сложность алгоритма Флойда–Уоршелла составляет \O{n^3}, ведь у нас просто три вложенных цикла. Также понятно, что алгоритму требуется граф, сохранённый в матрице смежности.

В заключение стоит сказать, что можно сделать много модификаций этого алгоритма, которые бы решали разные задачи (но не для больших графов, потому что алгоритм выполнялся бы долго).

Например, можно выводить сами кратчайшие пути, если запомнить, из какой вершины мы попали к текущему ребру: сначала возьмём $p_{i \to j} = i$, и если мы делаем обновление внутри цикла, то сделаем и $p_{i \to j} = p_{k \to j}$, а при выводе пути $i \to j$ нужно будет сначала вывести путь $i \to p_{i \to j}$, а после этого и вершину $j$.

Также можно использовать этот алгоритм для поиска кратчайших путей из одной вершины; для поиска \term{транзитивного замыкания} — проверки, что есть путь $i \to j$; для задач минимакса и максимина; для проверки наличия отрицательного цикла (просто запустим алгоритм ещё раз и все ячейки, в которых поменялись ответы будут иметь ответ $-\infty$). И ещё много других интересных задач, с которыми читатель может ознакомиться сам.
