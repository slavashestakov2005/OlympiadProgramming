\head{Кратчайшие пути}
Мы продолжаем изучать графы, и сегодня научимся искать \term{кратчайшие пути} между парой вершин, от одной вершины до всех остальных и между всеми парами вершин. Хоть алгоритмов и много, но все они (почти) достаточно понятны и частично основываются на уже пройденных алгоритмах. Кратчайшие пути очень часто встречаются в задачах, так что стоит их изучить.


\subhead{Кратчайшие пути от одной вершины до всех}
С минимальными остовными деревьями мы разобрались, поэтому можем переходить к кратчайшим путям. При этом хотелось бы начать с кратчайшего пути между парой вершин, но для этой задачи нет отдельного алгоритма, поэтому мы начнём с кратчайшего пути из одной вершины во все.

Оказывается, что и эту задачу мы уже умеем решать для невзвешенных графов с помощью BFS. Для этого в BFS будем поддерживать $d_i$ — номер слоя для вершины $i$, который нужно пересчитывать при добавлении вершины $i$ в очередь из-за ребра $x \to i$, как $d_i = d_x + 1$. Но всё же это частный случай для невзвешенных графов, а хочется уметь решать задачу в общем виде, поэтому перейдём к изучению алгоритмов для взвешенных графов.

\textbf{Алгоритм Дейкстры.} Этот алгоритм похож на смесь BFS и алгоритма Прима. И своей целью ставит определение $d_i$ — расстояние от стартовой вершины $s$ до вершины $i$. При этом во время работы алгоритма нам понадобится брать вершину с минимальным расстоянием, и из-за разных способов это сделать мы будем получать разные сложности.

\begin{box-algo}
    \begin{enumerate}
        \item Положим $d_s = 0$ и $d_u = \infty$\footnote{Здесь и далее константу $\infty$ нужно выбирать так, чтобы сумма $\infty + \infty$ ещё входила в тип данных!}, для $u \ne s$.
        \item Теперь в цикле будем выбирать необработанную вершину $u$ с минимальным расстоянием до ней (как это делать будет описано ниже). Обходим все рёбра $(u; v)$ и пытаемся обновить минимальное расстояние $d_v = \min(d_v, d_u + c)$, где $c$ — это стоимость ребра $(u, v)$.
    \end{enumerate}
\end{box-algo}

Собственно, это и есть весь алгоритм, теперь осталось понять, как искать вершину $u$.

Выбирать вершину $u$ можно с помощью массивов. Для этого дополнительно будем поддерживать список $used$, отвечающий за посещённость вершины (будем отмечать вершину $u$ в $used$, до обхода рёбер из $u$). И теперь для выбора минимальной вершины будем проходить по всем вершинам и выбирать ту, у которой $d_i$ минимальна и при этом она ещё не посещалась согласно списку $used$. Заканчивать же алгоритм мы можем или когда посещены все вершины, или когда посещена все КС (тогда мы сможем найти только $d_i = \infty$ среди не посещённых вершин).

Другой способ — это использовать множество / отображение или кучу $p$. Тогда в самом начале нам нужно добавить пару $(0; s)$ в $p$. А после этого на каждом шаге брать минимальную пару $(u, c)$ из $p$ и уже работать с этой вершиной. При этом после изменения расстояния до вершины $v$ нам нужно добавить ей в $p$ (в таком же формате $(v, d_v)$). Но понятно, что так одна и та же вершина $v$ может попасть в $p$ из-за разных вершин $u$, а обрабатывать мы её хотим только один раз. Поэтому если нам позволяет структура данных $p$, то перед добавлением нужно будет удалить старое значение для вершины $v$, что мы и будем делать для встроенных в C++ множеств и отображений, а также можем сделать для декартового дерева, написанного самостоятельно. А если же мы используем встроенную в C++ кучу или пишем её сами, то операции удаления в ней нет, поэтому обходить все рёбра из $u$ мы будем только в случае, когда $c = d_u$ (то есть между добавлением пары в кучу и обновлением вершин не было других обновлений). Заканчивать же алгоритм мы в любом случае будем, когда $p$ станет пусто.

Алгоритм, конечно, хороший и понятный, но в общем есть одна проблема — он не всегда работает. Пусть мы уже правильно обработали какое-то множество вершин (нашли кратчайшие пути до них) и все рёбра, выходящие из них, а сейчас обрабатываем вершину $u$. Тогда для неё $d_u$ будет правильным ответом только если нет рёбер отрицательного веса $w$, ведь если они существуют, то может найтись ещё какая-то вершина $x$ такая, что $d_x > d_u$, но при этом $d_x + w < d_u$, а значит для вершину $u$ у нас пока не правильный ответ. Но вот если все веса неотрицательны то точно всё хорошо, ведь тогда для любого $x$ будем иметь $d_x > d_u$ и $d_x + w > d_u$.

Поэтому алгоритм Дейкстры работает только для графов без рёбер отрицательного веса, а его сложность для случая с массивами будет \O{n^2 + m}, потому что мы для каждого шага перебираем все вершины и плюс просматриваем все ребра. А вот если использовать правильные структуры данных, то имеем сложность \O{m \log n}, потому что в худшем случае каждое ребро обновляет кратчайшие пути, а на одну операцию с $p$ требуется $O(\log n)$ операций в случаи с удаление повторов и $O(\log m) = O(\log n^2) = O(2 \log n) = O(\log n)$ если повторы не удалять :) Всего же таких операций $m$ для рёбер 
$n$ для взятия минимальной вершины, поэтому на самом деле сложность составляет \O{(n + m) \log n}.

Также стоит сказать, что есть решение со сложностью \O{n \log n + m}, если использовать \term{Фибоначчиевы кучи}, и линейный алгоритм Торупа, но это тоже остаётся для самостоятельного изучения читателями.

\textbf{Алгоритм Форда–Беллмана.} На самом деле, разобранная выше реализация алгоритма Дейкстры на основе кучи без удаления лишних пар всё же умеет обрабатывать отрицательные веса рёбер (просто работает несколько дольше, потому что делает несколько обновлений для одной вершины), но ломается, если в графе есть цикл отрицательного веса (обновления в алгоритме Дейкстры происходят бесконечно). Именно для этого и нужно использовать очень простой алгоритм Форда–Беллмана, вычисляющий $d_i$ минимальное расстояние от $s$ до $i$:

\begin{box-algo}
    \begin{enumerate}
        \item Изначально принимаем $d_s = 0$ и $d_u = \infty$, для $u \ne s$.
        \item Теперь повторим цикл $n-1$ раз, в каждом из которых для всех рёбер $(u, v)$ с весом $c$ сделаем \term{релаксацию} (обновление ответа): $d_v = \min(d_v, d_u + c)$. 
    \end{enumerate}
\end{box-algo}

И это собственно весь алгоритм!

А если нужно проверить, есть ли цикл отрицательного веса, то достаточно ещё раз сделать релаксацию для всех рёбер и проверить, поменялись ли ответы: если поменялись, то есть цикл отрицательного веса, если нет — то и цикла нет. Просто, правда? :)

Но и в таком простом алгоритме можно сделать пару модификаций. Во-первых, если на каком-то шаге не один $d_i$ не обновился, то у нас уже есть ответ. А во-вторых, если нужно, то можно восстановить сами кратчайшие пути (как, собственно, и в алгоритме Дейкстры).

Теперь быстренько докажем правильность этого алгоритма. Заметим, что на $i$-ой итерации цикла мы получаем правильные ответы для всех вершин, кратчайшие расстояния до которых состоят из $i$ рёбер. Это утверждение очевидно, ведь на первом шаге мы посетим первое ребро и получим оптимальный ответ для первой вершины, на втором шаге точно посмотрим на второе ребро пути и получим ответ для второй вершины, и так далее, а на $i$-ом шаге как раз пройдём по $i$-ому ребро и получим ответ для этой вершины. А поскольку граф состоит из $n$ вершин, то самый длинный путь может состоять из $n - 1$ ребра, именно столько итераций цикла мы и делаем, а значит наш алгоритм корректен.

Также стоит сказать, что граф можно хранить и как список рёбер, и как список смежности, и тогда сложность этого алгоритма \O{n m}, хоть это читатель мог понять и сам :) А вот если мы работаем с матрицей смежности, то на каждом шаге цикла будем проходить всю матрицу и получим сложность \O{n^3}.


\subhead{Кратчайшие пути между всеми парами вершин}
Раз уж мы решали задачу для случая с одной стартовой вершиной, то теперь совсем усложним её и будем искать путь между всеми парами вершин. Наивные решения, которые $n$ раз бы запускали поиск расстояния от одной вершины нас не интересуют, потому что они получатся слишком сложными для $m = O(n^2)$: \O{n^3 \log n} для алгоритма Дейкстры и \O{n^4} для алгоритма Форда–Беллмана, а хочется найти алгоритм быстрее. Поэтому, можно бы начать бояться, что тут будет какой-нибудь очень сложный алгоритм, но на самом деле всё просто:

\begin{box-algo}
    \begin{enumerate}
        \item Сохраним граф в матрице смежности $g$ и в ячейку $(i, j)$ поставим $\infty$, если в графе нет ребра из $i$ в $j$, а иначе запишем в эту ячейку вес самого ребра. Также считаем, что в вершине можно оставаться: $g_{i \to i} = 0$ (если в графе разрешены петли, то пишем вес петель).
        \item Теперь сделаем цикл $n$ раз и на $k$-ом шаге цикла переберём все пары вершин $(i, j)$ и будем пытаться обновить ответ для этой пары через вершину $k$: $g_{i \to j} = \min(g_{i \to j}, g_{i \to k} + g_{k \to j})$.
    \end{enumerate}
\end{box-algo}

Вот и всё, мы получили рабочий алгоритм в 3 цикла и одну операцию!

Давайте докажем этот алгоритм, который основывается на динамическом программировании. Пусть $D_{i \to j}^k$ это оптимальный путь из $i$ в $j$, промежуточно проходящий только через первые $k$ вершин: $1,\ 2,\ \ldots,\ k$. Тогда понятна и основная формула перехода: $D_{i \to j}^{k + 1} = \min( D_{i \to j}^k, D_{i \to k}^k + D_{k \to j}^{k})$, ведь очередная вершина $k$ может как использоваться в пути $i \to j$, так и нет. Базой же динамики будут изначальные кратчайшие расстояния, не проходящие через другие вершины, которые являются весами рёбер: $k = 0$ и $D_{i \to j}^0 = g_{i \to j}$.

Но поскольку в нашей формуле мы вычисляем $D^{k + 1}$ только через $D^k$, то для ответов можно хранить не трёхмерную матрицу $n \times n \times k$, а ограничиться лишь двумя матрицами $n \times n$. А если понять, что от рассмотрения лишних вершин наш ответ не ухудшится, то можно смело хранить ответы для обоих итераций ($k$ и $k + 1$) в одном и том же массиве, именно поэтому мы и имеем такую простую формулу для алгоритма Флойда–Уоршелла (так называется то, что мы прошли).

Понятно, что сложность алгоритма Флойда–Уоршелла составляет \O{n^3}, ведь у нас просто три вложенных цикла. Также понятно, что алгоритму требуется граф, сохранённый в матрице смежности.

В заключение стоит сказать, что можно сделать много модификаций этого алгоритма, которые бы решали разные задачи (но не для больших графов, потому что алгоритм выполнялся бы долго).

Например, можно выводить сами кратчайшие пути, если запомнить, из какой вершины мы попали к текущему ребру: сначала возьмём $p_{i \to j} = i$, и если мы делаем обновление внутри цикла, то сделаем и $p_{i \to j} = p_{k \to j}$, а при выводе пути $i \to j$ нужно будет сначала вывести путь $i \to p_{i \to j}$, а после этого и вершину $j$.

Также можно использовать этот алгоритм для поиска кратчайших путей из одной вершины; для поиска \term{транзитивного замыкания} — проверки, что есть путь $i \to j$; для задач минимакса и максимина; для проверки наличия отрицательного цикла (просто запустим алгоритм ещё раз и все ячейки, в которых поменялись ответы будут иметь ответ $-\infty$). И ещё много других интересных задач, с которыми читатель может ознакомиться сам.
